---
source: Rmd
title: "Common Analyses"
teaching: 90
exercises: 30
questions:
- "What are the most common single cell RNA-Seq analyses?"
objectives:
- "Explain how to use RMarkdown with the new lesson template."
- "Demonstrate how to include pieces of code, figures, and challenges."
keypoints:
- "Edit the .Rmd files not the .md files"
- "Run `make serve` to knit documents and preview lesson website locally"
---

```{r, include=FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("05-")

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(Seurat))

data_dir <- '../data'
```

```{r seed, echo = FALSE}
# set a seed for reproducibility in case any randomness used below
set.seed(1418)
```


## Read Data from Previous Lesson

```{r load_data}
liver <- readRDS(file.path(data_dir, 'lesson04.rds'))
```

## A Note on Seurat Functions

The Seurat package is set up so that we primarily work with a 
Seurat object containing our single cell data and metadata.
Let's say we are working with our Seurat object `liver`. 
The usual way we might call a function to do something with our
data looks like:
```
liver <- DoSomething(liver, param1 = TRUE, param2 = 0.3)
```

However, since the `DoSomething()` function returns the modified
Seurat object, we can also pipe together multiple commands to do
multiple things to our object. That could look something like:
```
liver <- DoSomething(liver, param1 = TRUE, param2 = 0.3) %>%
    DoSomethingElse(param1 = 3) %>%
    DoAThirdThing(param1 = c(1, 4, 6))
```

We can just as well use the piping operator `%>%` even if 
we are calling only one function:
```
liver <- liver %>%
    DoSomething(param1 = TRUE, param2 = 0.3)
```

In this lesson (and elsewhere in the course) we may alternate between
these slightly different coding styles. Please ask us for clarification
if you are having difficulty seeing how our example code is 
doing what it is supposed to do.

### Normalization

Instead of working with raw count data measured across cells
that were sequenced to highly variable depths, we conduct
normalization to try to make gene expression values follow
a more stable distribution as well as being more comparable
between cells.

Single cell gene expression
count data is usually approximately log-normally distributed. 
Many statistical methods work best when the data is normally distributed. 
We also would like to correct for variability in sequencing depth 
between cells, the nature of which is purely technical.
Log normalization will give us normalized gene expression which represents
the log of the number of counts per 10,000 reads.

```{r normalization, message=FALSE}
liver <- liver %>%
            NormalizeData(normalization.method = "LogNormalize")
```

This method of normalizing is pretty simple. The way it works is
to follow a simple formula like
`norm_count = log((count + 1)/total_counts) * 10000`
where `total_counts` is the total number of reads in each cell.

There are other normalization methods that are more complicated and
may outperform the log normalization method. Two examples are:

 * Normalization based on multinomial methods as outlined by
 [Townes et al. 2019](https://pubmed.ncbi.nlm.nih.gov/31870412/)
 * Normalization using regularized negative binomial regression
 [Hafemeister and Satija 2019](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1), 
 with a [Seurat vignette here](https://satijalab.org/seurat/articles/sctransform_vignette.html)
 
However, no normalization method has been demonstrated to be universally
and unambiguously better than simple log normalization.

### Finding Variable Features

Next we will find a subset of features showing high cell-to-cell variation 
in the dataset (that is, they are highly expressed in some cells and lowly
expressed in others). 

```{r var_features, message=FALSE, warning=FALSE}
liver <- liver %>% 
              FindVariableFeatures(nfeatures = 2000)

# Identify the 25 most highly variable genes
top25 <- head(VariableFeatures(liver), 25)

plot1 <- VariableFeaturePlot(liver)
plot2 <- LabelPoints(plot = plot1, points = top25, xnudge = 0, 
                     ynudge = 0, repel = TRUE)
plot2
```

## Cell cycle assignment 

We will also show how to predict cell cycle state.
This approach is outlined in the Seurat vignette at
[this link](https://satijalab.org/seurat/articles/cell_cycle_vignette.html).


```{r cellcycle}
cc.genes <- readLines(file.path(data_dir,
  'regev_lab_cell_cycle_genes_mm.fixed.txt'))
s.genes <- cc.genes[1:43]
g2m.genes <- cc.genes[44:98]

liver <- CellCycleScoring(liver, s.features=s.genes, 
  g2m.features=g2m.genes, set.ident=FALSE)
```

Seurat will provide a quantitative estimate of the cell's chance of being
in different phases of the cell cycle `S.Score` and `G2M.Score`, as well as
a categorical prediction of which phase the cell is in 
(`Phase` -- G1, G2M, S).

### Scale Data

Now we apply a linear transformation that is often used in initial 
scRNA-Seq processing. This transformation standardizes the expression of
each gene, setting the mean across cells to 0 and variance to 1. 
This helps all genes to contribute to the inferred variability rather
than just the highly-expressed genes.

We will "regress out" the signals of technical confounders including
%MT and the number of genes expressed. We might also choose to regress out
other variables such as cell cycle stage (if we wish to examine 
cellular heterogeneity independent of cell cycle), number of UMIs,
etc.


```{r scaling, message=FALSE}
liver <- liver %>%
    ScaleData(vars.to.regress = c("percent.mt", "nFeature_RNA"))
```

### Principal Component Analysis

Next we reduce the dimensionality of the data. You have probably heard
of PCA as a technique for summarizing major axes of variation in a dataset.
Here, we perform PCA on the single cell gene expression data in order to
place each cell in a multidimensional space with lower dimension (say 20-40)
than the complete expression matrix (~20,000 genes).

```{r PCA, message=FALSE}
liver <- liver %>%
              RunPCA(verbose = FALSE, npcs = 100)
```

It is usually not very useful to view the raw PCs themselves.
There's nothing obvious that we can glean from the following PC plot:

```{r pcplot}
DimPlot(liver, reduction = "pca")
```

Instead we will take some of the PCs and use them for a further
summarization of the data. Namely, we will use the PCs as input to the
UMAP (or t-SNE) algorithm which projects our cells onto a 2D space
(the computer screen). 

A significant challenge in scRNA-Seq is deciding how many PCs to use.
You can think of each PC as capturing pathway-level transcriptional variation
across the cells in your dataset. Thus even if the transcriptome is sparse
within each cell (it is), you can still compare different cells across major
axes of variation. We don't want to use too *few* PCs, otherwise we 
might miss significant axes of variation (e.g. a cell subtype or minor cell 
type). We also don't want to use too *many* PCs since, as you go out in PC-space,
the PCs increasingly represent more noise and less biological reality.

We will use a very simple method to choose the number of PCs: the elbow
method. Using this method we look for where the elbow plot stops dropping
precipitously.
```{r elbow}
ElbowPlot(liver, ndims = 100)
```

Let's zoom in more and see what things like under 50 PCs.
```{r elbow2}
ElbowPlot(liver, ndims = 50)
```

We would say that the standard deviation in PCs really starts to stablize
around N = 24 PCs. Let's use this value moving forward.
For a more in-depth analysis we would try a variety of values and 
attempt to decide which value gives us the results that are most 
biologically sensible. 

There is also a function in Seurat, `JackStraw()`, that one may use
to try to determine the statistical significance of principal 
component scores. Specifically, it randomly permutes a subset of data, 
and calculates projected PCA scores for these random genes. Then it
compares the PCA scores for the random genes with the observed PCA scores 
to determine statistical signifance. We are not using this function here
because it is a bit slow and because it often does not give any better 
results than the simple method of looking at an elbow plot.

All this said, the major question here -- how many PCs to select in order
to capture the important variation within your scRNA-Seq data in a
reduced dimension space -- is still unresolved and your best bet is 
to explore different values and see what they give you!

```{r elbow3}
num_pc <- 24
ElbowPlot(liver, ndims = 40) + geom_vline(xintercept = num_pc)
```

<!-- Do we need to do batch correction with Harmony? The authors of the
liver cell atlas did it ...
See https://github.com/guilliottslab/scripts_GuilliamsEtAll_Cell2022/blob/main/3b_Harmony.R
-->

## Dimensionality reduction (UMAP, tSNE, etc) 

As mentioned above, dimensionality reduction allows you to actually 
visualize your data! The two methods below are widely used in the
single cell community.

> Uniform Manifold Approximation and Projection (UMAP) [van der Maaten & Hinton, 2008](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf).

> t-Distributed Stochastic Neighbor Embedding (t-SNE) [McUnnes et al](https://arxiv.org/abs/1802.03426) 

These methods generally do a very effective job of putting similar points near each other in the reduced-dimensionality space. Thus cells from 
the same clusters are likely to be placed in the same region of the UMAP/t-SNE.

UMAP is more widely used the t-SNE at the current time.
Note that you should caution yourself not to overinterpret UMAP plots.
Although UMAP does optimize both local and global similarity for points
being projected onto a 2D space, UMAP contains no guarantee that similar points
must be near each other.

```{r umap, warning=FALSE}
liver <- RunUMAP(liver, reduction = 'pca', dims = 1:num_pc, 
    verbose = FALSE)
```

## Clustering 

Seurat uses a graph-based approach to cluster cells with similar
transcriptomic profiles. 
We start by constructing the shared nearest-neighbor graph. This
computes a distance metric between the cells (in PC-space) and 
constructs the shared nearest-neighbor graph by calculating the
neighborhood overlap (Jaccard index) between every cell and its 
20 (by default) nearest neighbors.
Then the shared nearest-neighbor graph is used to identify
cell clusters using a modularity optimization based clustering
algorithm. 
The Seurat help pages for the functions below,
[FindNeighbors](https://satijalab.org/seurat/reference/findneighbors)
and 
[FindClusters](https://satijalab.org/seurat/reference/findclusters),
provide some references if you are interested in digging into
further details of this clustering procedure.


```{r seurat3, message=FALSE}
liver <- FindNeighbors(liver, reduction = 'pca', 
                       dims = 1:num_pc, verbose = FALSE) %>%
           FindClusters(verbose = FALSE, resolution = 0.3)
UMAPPlot(liver, label = TRUE, label.size = 6)
```

Note that we are using the principal components computed from 
normalized gene expression to compute UMAP
dimensionality reduction and we are also using the principal 
components to compute a shared nearest neighbor graph and 
find clusters. These two tasks are independent and could be done in
either order. Very often the points that are near each other in
UMAP space are also near neighbors and belong to the same cluster,
but this is not always the case.


## Saving

We will again use the Seurat object in the next lesson. Save it now and we will 
load it at the beginning of the next lesson. 

```{r save_seurat}
saveRDS(liver, file = file.path(data_dir, 'lesson05.rds'))
```


## Session Info

```{r session_info}
sessionInfo()
```
